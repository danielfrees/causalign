{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of Bansal et al. (2023)'s ITVReg\n",
    "\n",
    "Found the original code (messy) at https://github.com/pbansal5/causal-recommendations. Going to try to clean up and replicate results. In particular the interventions are unclear both in their description in the paper and in the code, so some liberty may need to be taken there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielfrees/miniconda3/envs/causalign/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# removing xclib requirement since it is a small library and does not support building on \n",
    "# new versions of python. Riddled with errors, wasn't able to patch all of them quickly. \n",
    "\n",
    "# nagame also removed, not even working in the OG work code lol\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import os\n",
    "import transformers as ppb\n",
    "from transformers import RobertaModel, AutoConfig\n",
    "import warnings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "warnings.filterwarnings('ignore')\n",
    "# from xclib.data.data_utils import read_sparse_file\n",
    "import copy\n",
    "from transformers import get_scheduler,AdamW\n",
    "from transformers import AutoTokenizer\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug\n",
    "import nltk\n",
    "# import xclib.evaluation.xc_metrics as xc_metrics\n",
    "# import xclib.data.data_utils as data_utils\n",
    "import scipy.sparse as sp\n",
    "# from ngame.nns import exact_search\n",
    "\n",
    "\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "torch.set_default_device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_DIR = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1WuquxCAg8D4lKr-eZXPv4nNw2S2lm7_E\n",
      "From (redirected): https://drive.google.com/uc?id=1WuquxCAg8D4lKr-eZXPv4nNw2S2lm7_E&confirm=t&uuid=4fde14c7-2014-4a82-86cf-654b19437f07\n",
      "To: /Users/danielfrees/Desktop/causalign/notebooks/data/LF-AmazonTitles-131K.raw.zip\n",
      " 56%|█████▋    | 138M/245M [04:56<09:59, 178kB/s]  "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "# Set the directory to store data (no need to set TOP_DIR)\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Step 1: Download the dataset from Google Drive using the correct link\n",
    "url = \"https://drive.google.com/uc?id=1WuquxCAg8D4lKr-eZXPv4nNw2S2lm7_E\"\n",
    "output_zip = os.path.join(data_dir, 'LF-AmazonTitles-131K.raw.zip')\n",
    "gdown.download(url, output_zip, quiet=False)\n",
    "\n",
    "# Step 2: Extract the downloaded .zip file\n",
    "with zipfile.ZipFile(output_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)\n",
    "\n",
    "# Step 3: Load the compressed JSON data from 'trn.json.gz', 'tst.json.gz', and 'lbl.json.gz'\n",
    "def load_gz_json_line_by_line(file_path):\n",
    "    data = []\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error decoding JSON on line: {line}\")\n",
    "    return data\n",
    "\n",
    "# Paths for train, test, and label JSON data\n",
    "unzipped_dir = \"LF-Amazon-131K\"\n",
    "train_data_path = os.path.join(data_dir, unzipped_dir, 'trn.json.gz')\n",
    "test_data_path = os.path.join(data_dir, unzipped_dir, 'tst.json.gz')\n",
    "label_data_path = os.path.join(data_dir, unzipped_dir, 'lbl.json.gz')\n",
    "\n",
    "# Load the datasets line by line\n",
    "train_data = load_gz_json_line_by_line(train_data_path)\n",
    "test_data = load_gz_json_line_by_line(test_data_path)\n",
    "label_data = load_gz_json_line_by_line(label_data_path)\n",
    "\n",
    "# Step 4: Optionally load the filter label files (if needed)\n",
    "filter_train_path = os.path.join(data_dir, unzipped_dir, 'filter_labels_train.txt')\n",
    "filter_test_path = os.path.join(data_dir, unzipped_dir, 'filter_labels_test.txt')\n",
    "\n",
    "with open(filter_train_path, 'r') as f:\n",
    "    filter_train = f.readlines()\n",
    "\n",
    "with open(filter_test_path, 'r') as f:\n",
    "    filter_test = f.readlines()\n",
    "\n",
    "# Step 5: Print out some information about the loaded datasets\n",
    "print(f\"Loaded {len(train_data)} training records\")\n",
    "print(f\"Loaded {len(test_data)} testing records\")\n",
    "print(f\"Loaded {len(label_data)} labels\")\n",
    "\n",
    "# Optionally print a sample to see the structure\n",
    "if train_data:\n",
    "    print(\"Sample training record:\", train_data[0])\n",
    "if test_data:\n",
    "    print(\"Sample test record:\", test_data[0])\n",
    "if label_data:\n",
    "    print(\"Sample label:\", label_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sparse matrix shape: (294805, 131073)\n",
      "Testing sparse matrix shape: (134835, 131073)\n",
      "Training sparse matrix non-zero elements: 674996\n",
      "Testing sparse matrix non-zero elements: 284746\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Example: Using the data from earlier\n",
    "\n",
    "# Assume train_data, test_data, and label_data are already loaded from the JSON files\n",
    "# Here we'll use the 'target_ind' and 'target_rel' fields to build sparse matrices\n",
    "\n",
    "def create_sparse_matrix(data, num_rows, num_cols):\n",
    "    \"\"\"Create a sparse matrix from 'target_ind' and 'target_rel'.\"\"\"\n",
    "    row_indices = []\n",
    "    col_indices = []\n",
    "    values = []\n",
    "    \n",
    "    for row, record in enumerate(data):\n",
    "        indices = record['target_ind']\n",
    "        rels = record['target_rel']\n",
    "        row_indices.extend([row] * len(indices))\n",
    "        col_indices.extend(indices)\n",
    "        values.extend(rels)\n",
    "    \n",
    "    # Create a sparse matrix in CSR format\n",
    "    sparse_matrix = sp.csr_matrix((values, (row_indices, col_indices)), shape=(num_rows, num_cols))\n",
    "    \n",
    "    return sparse_matrix\n",
    "\n",
    "# Get the dimensions\n",
    "num_train_samples = len(train_data)\n",
    "num_test_samples = len(test_data)\n",
    "num_labels = len(label_data)  # This should be the number of columns (unique target indices)\n",
    "\n",
    "# Create the sparse matrices\n",
    "train_sparse_matrix = create_sparse_matrix(train_data, num_train_samples, num_labels)\n",
    "test_sparse_matrix = create_sparse_matrix(test_data, num_test_samples, num_labels)\n",
    "\n",
    "# Example: Print information about the created sparse matrix\n",
    "print(f\"Training sparse matrix shape: {train_sparse_matrix.shape}\")\n",
    "print(f\"Testing sparse matrix shape: {test_sparse_matrix.shape}\")\n",
    "\n",
    "# If you want to see the non-zero elements count:\n",
    "print(f\"Training sparse matrix non-zero elements: {train_sparse_matrix.nnz}\")\n",
    "print(f\"Testing sparse matrix non-zero elements: {test_sparse_matrix.nnz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, datadir,mapping, device,split):\n",
    "        self.lbl_size = 131073\n",
    "        self.datadir = datadir\n",
    "        self.device=device\n",
    "        self.size = 294805 if split =='trn' else 134835\n",
    "        if split == 'trn':\n",
    "            self.point_text_files = [x.strip() for x in open('%s/raw/trn_X.title.txt'%self.datadir).readlines()]\n",
    "        else :\n",
    "            self.point_text_files = [x.strip() for x in open('%s/raw/tst_X.title.txt'%self.datadir).readlines()]\n",
    "        self.label_text_files = [x.strip() for x in open('%s/raw/Y.title.txt'%self.datadir).readlines()]\n",
    "        self.mat_mapping = mapping\n",
    "        self.mapping = mapping.nonzero()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "        self.maxsize=32\n",
    "        self.aug = naw.SynonymAug(aug_src='wordnet',aug_max=5)\n",
    "        # aug = naw.WordEmbsAug(model_type='word2vec',model_path = './wiki-news-300d-1M.vec')\n",
    "        temp = np.fromfile('%s/tst_filter_labels.txt'%self.datadir, sep=' ').astype(int)\n",
    "        temp = temp.reshape(-1, 2).T\n",
    "        self.tst_filter_mat = sp.coo_matrix((np.ones(temp.shape[1]), (temp[0], temp[1])), tst_X_Y.shape).tocsr()\n",
    "\n",
    "    def __getitem__(self,index,augment=True):\n",
    "        point_data,label_data = self.convert_joint(self.point_text_files[self.mapping[0][index]],self.label_text_files[self.mapping[1][index]],augment=augment)\n",
    "#         point_data = self.convert(self.point_text_files[self.mapping[0][index]],augment=augment)\n",
    "#         label_data = self.convert(self.label_text_files[self.mapping[1][index]],augment=augment)\n",
    "        return (torch.Tensor(point_data['input_ids'][0]).to(device),\n",
    "               torch.Tensor(label_data['input_ids'][0]).to(device),\n",
    "               torch.Tensor(point_data['attention_mask'][0]).to(device),\n",
    "               torch.Tensor(label_data['attention_mask'][0]).to(device))\n",
    "    \n",
    "    def convert_joint(self,textp,textl,augment=True):\n",
    "        if augment : \n",
    "            textp=self.aug.augment(textp,n=1)\n",
    "            textl=self.aug.augment(textl,n=1)\n",
    "\n",
    "        combined = textp.split(' ')+textl.split(' ')\n",
    "        split_point = int(np.random.uniform(1,len(combined)))\n",
    "        textp = ' '.join(combined[:split_point])\n",
    "        textl = ' '.join(combined[split_point:])\n",
    "        \n",
    "        return (self.tokenizer(textp,add_special_tokens = True,\n",
    "                         truncation=True,return_tensors = 'np',\n",
    "                         return_attention_mask = True,padding = 'max_length',max_length=self.maxsize),\n",
    "                self.tokenizer(textl,add_special_tokens = True,\n",
    "                         truncation=True,return_tensors = 'np',\n",
    "                         return_attention_mask = True,padding = 'max_length',max_length=self.maxsize))\n",
    "    \n",
    "    def convert(self,text,augment=True):\n",
    "        if augment : \n",
    "            text=self.aug.augment(text,n=1)\n",
    "        return self.tokenizer(text,add_special_tokens = True,\n",
    "                         truncation=True,return_tensors = 'np',\n",
    "                         return_attention_mask = True,padding = 'max_length',max_length=self.maxsize)\n",
    "    \n",
    "    def get_embeds(self,model,batch_size,device):\n",
    "        labels = self.convert(self.label_text_files,augment=False)\n",
    "        points = self.convert(self.point_text_files,augment=False)\n",
    "        num_labels = labels['input_ids'].shape[0]\n",
    "        num_points = points['input_ids'].shape[0]\n",
    "        with torch.no_grad():\n",
    "            label_embeds = []\n",
    "            for i in range(0,num_labels,batch_size):\n",
    "                label_embeds.append(model.get_embed({'input_ids':torch.LongTensor(labels['input_ids'][i:i+batch_size]).to(device),\n",
    "                                          'attention_mask':torch.LongTensor(labels['attention_mask'][i:i+batch_size]).to(device)}).cpu())\n",
    "            label_embeds = torch.cat(label_embeds,dim=0)\n",
    "\n",
    "            point_embeds = []\n",
    "            for i in range(0,num_points,batch_size):\n",
    "                point_embeds.append(model.get_embed({'input_ids':torch.LongTensor(points['input_ids'][i:i+batch_size]).to(device),\n",
    "                                          'attention_mask':torch.LongTensor(points['attention_mask'][i:i+batch_size]).to(device)}).cpu())\n",
    "            point_embeds = torch.cat(point_embeds,dim=0)\n",
    "        return point_embeds,label_embeds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mapping[0])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    point_ids,label_ids,point_masks,label_masks = zip(*batch)\n",
    "    return {'input_ids':torch.stack(point_ids,dim=0).long(),'attention_mask':torch.stack(point_masks,dim=0).long()},{'input_ids':torch.stack(label_ids,dim=0).long(),'attention_mask':torch.stack(label_masks,dim=0).long()}\n",
    "\n",
    "\n",
    "class PrecEvaluator():\n",
    "    def __init__(self, dataset, device,batch_size):\n",
    "        self.K = 5\n",
    "        self.metric = \"P\"\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.filter_mat = dataset.tst_filter_mat\n",
    "        self.best_score = -9999999\n",
    "\n",
    "    def __call__(self,model):\n",
    "        xembs,yembs = self.dataset.get_embeds(model,self.batch_size,self.device)\n",
    "        torch.cuda.empty_cache()\n",
    "        es = exact_search({'data': yembs.cpu().numpy(), 'query': xembs.cpu().numpy(), 'K': 100, 'device': self.device})\n",
    "        score_mat = es.getnns_gpu()\n",
    "        if self.filter_mat is not None:\n",
    "            self._filter(score_mat)\n",
    "        res = self.printacc(score_mat, X_Y=self.dataset.mat_mapping, K=self.K)\n",
    "        recall = xc_metrics.recall(score_mat, self.dataset.mat_mapping, k=100)*100\n",
    "        print(f'Recall@100: {\"%.2f\"%recall[99]}')        \n",
    "        score = res[str(self.K)][self.metric]\n",
    "        return score\n",
    "    \n",
    "    def _filter(self,score_mat):\n",
    "        temp = self.filter_mat.tocoo()\n",
    "        score_mat[temp.row, temp.col] = 0\n",
    "        del temp\n",
    "        score_mat = score_mat.tocsr()\n",
    "        score_mat.eliminate_zeros()\n",
    "        return score_mat\n",
    "\n",
    "            \n",
    "    def printacc(self,score_mat, K = 5, X_Y = None, disp = True):\n",
    "        if X_Y is None: X_Y = tst_X_Y\n",
    "\n",
    "        acc = xc_metrics.Metrics(X_Y.tocsr().astype(np.bool), None)\n",
    "        metrics = np.array(acc.eval(score_mat, K))*100\n",
    "        df = pd.DataFrame(metrics)\n",
    "\n",
    "        df.index = ['P', 'nDCG']\n",
    "        \n",
    "        df.columns = [str(i+1) for i in range(K)]\n",
    "        if disp: display(df.round(2))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTModel(torch.nn.Module):\n",
    "    def __init__(self,gamma):\n",
    "        super().__init__()\n",
    "        self.encoder = SentenceTransformer('msmarco-distilbert-base-v3')\n",
    "        self.rep_dim = self.encoder.get_sentence_embedding_dimension()\n",
    "        self.hidden_dim = 1024\n",
    "        self.target_encoder = copy.deepcopy(self.encoder).requires_grad_(False)\n",
    "        self.predictor = torch.nn.Sequential(torch.nn.Linear(self.rep_dim,self.hidden_dim),\n",
    "                                             torch.nn.ReLU(),torch.nn.Linear(self.hidden_dim,self.rep_dim))\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        flip = np.random.binomial(1,0.5)\n",
    "        if (flip == 0):\n",
    "            x_embeds = torch.nn.functional.normalize(self.predictor(self.encoder(x)['sentence_embedding']),dim=-1)\n",
    "            y_embeds = torch.nn.functional.normalize(self.target_encoder(y)['sentence_embedding'],dim=-1).clone().detach()\n",
    "        else:\n",
    "            y_embeds = torch.nn.functional.normalize(self.predictor(self.encoder(y)['sentence_embedding']),dim=-1)\n",
    "            x_embeds = torch.nn.functional.normalize(self.target_encoder(x)['sentence_embedding'],dim=-1).clone().detach()\n",
    "        scores = x_embeds@y_embeds.T\n",
    "        positives = torch.diag(scores).sum()\n",
    "        negatives = scores.sum()-positives\n",
    "        positives /= scores.shape[0]\n",
    "        negatives /= ((scores.shape[0]-1)*(scores.shape[0]))\n",
    "        self.update_target()\n",
    "        return positives,negatives\n",
    "    \n",
    "    def get_embed(self,x):\n",
    "        return torch.nn.functional.normalize(self.encoder(x)['sentence_embedding'],dim=-1)\n",
    "        \n",
    "    \n",
    "    def update_target(self):\n",
    "        target_dict = self.target_encoder.state_dict()\n",
    "        online_dict = self.encoder.state_dict()\n",
    "        for key in online_dict.keys():\n",
    "            target_dict[key] = target_dict[key]*self.gamma + online_dict[key]*(1-self.gamma)\n",
    "        self.target_encoder.load_state_dict(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.995\u001b[39m\n\u001b[1;32m      9\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBERTModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m results_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/t-pbansal/logs/tensorboard/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124mgamma_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(expname,gamma,batch_size)\n\u001b[1;32m     13\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(log_dir\u001b[38;5;241m=\u001b[39mresults_dir)\n",
      "File \u001b[0;32m~/miniconda3/envs/causalign/lib/python3.11/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/causalign/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/causalign/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/causalign/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/causalign/lib/python3.11/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/causalign/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/causalign/lib/python3.11/site-packages/torch/cuda/__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "expname = 'WordNetAugCut'\n",
    "datadir='/home/t-pbansal/datasets/LF-AmazonTitles-131K'\n",
    "trn_X_Y = train_sparse_matrix\n",
    "tst_X_Y = test_sparse_matrix\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 1024\n",
    "max_epoch = 500\n",
    "gamma = 0.995\n",
    "iteration = 0\n",
    "\n",
    "model = BERTModel(gamma = gamma).to(device)\n",
    "results_dir = '/home/t-pbansal/logs/tensorboard/%s_%fgamma_%dbs'%(expname,gamma,batch_size)\n",
    "writer = SummaryWriter(log_dir=results_dir)\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(BertDataset(datadir=datadir,mapping=trn_X_Y,split='trn',device=device),batch_size=batch_size,drop_last=True,shuffle=True,collate_fn=collate_fn)\n",
    "test_dataloader = torch.utils.data.DataLoader(BertDataset(datadir=datadir,mapping=tst_X_Y,split='tst',device=device),batch_size=batch_size,drop_last=True,shuffle=True,collate_fn=collate_fn)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4,weight_decay=1e-6)\n",
    "num_training_steps = max_epoch * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=1000,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "evaluator = PrecEvaluator(test_dataloader.dataset,device,100)\n",
    "best_score = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 0 at iteration 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epoch):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m at iteration \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(epoch,iteration))\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _,(x,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_dataloader\u001b[49m):\n\u001b[1;32m      4\u001b[0m         positives,negatives \u001b[38;5;241m=\u001b[39m model(x,y)\n\u001b[1;32m      5\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mpositives\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    print (\"starting epoch %d at iteration %d\"%(epoch,iteration))\n",
    "    for _,(x,y) in enumerate(train_dataloader):\n",
    "        positives,negatives = model(x,y)\n",
    "        loss = -positives\n",
    "        exit()\n",
    "        if (iteration %100  == 0):\n",
    "            writer.add_scalar('train/positives',positives,iteration)\n",
    "            writer.add_scalar('train/negatives',negatives,iteration)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        iteration += 1\n",
    "    if(epoch %1 == 0):\n",
    "        positives,negatives,count = 0,0,0\n",
    "        with torch.no_grad():\n",
    "            for _,(x,y) in enumerate(test_dataloader):\n",
    "                positives_,negatives_ = model(x,y)\n",
    "                positives += positives_\n",
    "                negatives += negatives_\n",
    "                count += 1\n",
    "        score = evaluator.__call__(model)\n",
    "        writer.add_scalar('val/P@5',score,iteration)\n",
    "        writer.add_scalar('val/positives',positives/count,iteration)\n",
    "        writer.add_scalar('val/negatives',negatives/count,iteration)\n",
    "        if (score < best_score):\n",
    "            best_score = score\n",
    "            torch.save(model.state_dict(),os.path.join(results_dir,'checkpoint.pt'))\n",
    "            print ('saved checkpoint for epoch %d'%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
